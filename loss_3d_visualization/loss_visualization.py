import sys
import os
sys.path.insert(1, os.path.join(sys.path[0], '..'))

import matplotlib
matplotlib.use("Agg")
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

import torch
import numpy as np
from utils.utils import load_parameters, stack_tensors
from datasets.datasets import *
import torch.nn as nn
from torch.autograd import Variable
import pickle
import random


def generate_rand_direction_vectors(model):
    directions = []

    for param in model.parameters():
        dims = list(param.size())
        parameter_norm = np.linalg.norm(param.data)
        # Create direction vectors for each filter with matching dimenions
        initial_direction_matrix = np.random.normal(size=dims)
        direction_norm = np.linalg.norm(initial_direction_matrix)

        scaled_direction_matrix = (initial_direction_matrix / direction_norm) * parameter_norm
        directions.append(scaled_direction_matrix)

    return directions


def calculate_loss(model, dataloader, loss_fct, is_cuda=True):
    model.eval()

    num_samples = len(dataloader.dataset)
    total_loss = 0

    for batch_idx, (x, y) in enumerate(dataloader):

        if is_cuda:
            x = Variable(x.cuda())
            y = Variable(y.cuda())
        else:
            x = Variable(x)
            y = Variable(y)

        # Calculate loss
        y_model = model(x)
        loss = loss_fct(y_model, y).sum()
        total_loss += loss.data[0]

    return total_loss / num_samples


def generate_plot_values(model, size, increment, direction_one, direction_two, dataloader_list,
                         loss_fct, is_cuda=True):
    points = []

    for alpha in np.arange(-size, size+increment, increment):
        for beta in np.arange(-size, size+increment, increment):
            total_loss = 0
            start_time = time.time()

            # Modify parameters
            for param, dir_one, dir_two in zip(model.parameters(), direction_one, direction_two):
                if is_cuda:
                    param.data += torch.FloatTensor((alpha*dir_one + beta*dir_two)).cuda()
                else:
                    param.data += torch.FloatTensor((alpha*dir_one + beta*dir_two))


            # Calculate the loss for each datatype
            for dataloader in dataloader_list:
                loss = calculate_loss(model, dataloader, loss_fct, is_cuda)
                total_loss += loss


            # Reverse the modification
            for param, dir_one, dir_two in zip(model.parameters(), direction_one, direction_two):
                if is_cuda:
                    param.data -= torch.FloatTensor((alpha*dir_one + beta*dir_two)).cuda()
                else:
                    param.data -= torch.FloatTensor((alpha*dir_one + beta*dir_two))

            points.append([alpha, beta, total_loss])
            print(alpha, beta, total_loss, round(time.time() - start_time, 1), "seconds")

    return points

if __name__ == '__main__':
    parameters = load_parameters(sys.argv[1])
    output_directory_name = sys.argv[2]

    adversarial_vector_type = None
    if len(sys.argv) == 4:
        adversarial_vector_type = sys.argv[3]

    if eval(parameters['general']['use_seed']):
        seed_val = int(parameters['general']['seed'])
        random.seed(seed_val)
        torch.manual_seed(seed_val)

    base_output_directory = parameters['dataset']['output_directory']
    experiment_name = parameters['general']['experiment_name']
    training_method = parameters['general']['training_method']
    num_files_used = int(parameters['dataset']['num_files_to_use'])

    print(experiment_name, training_method, num_files_used, "files each type")

    if not os.path.exists(base_output_directory):
        os.mkdir(base_output_directory)

    output_directory = os.path.join(base_output_directory, output_directory_name)
    if not os.path.exists(output_directory):
        os.mkdir(output_directory)

    model_filepath = parameters['general']['model_weights_path']
    is_cuda = eval(parameters['general']['is_cuda'])
    
    if is_cuda:
        model = torch.load(model_filepath)
    else:
        model = torch.load(model_filepath, map_location=lambda storage, loc: storage)

    # Generate random direction vectors scaled to model parameters
    delta_direction = generate_rand_direction_vectors(model)
    eta_direction = generate_rand_direction_vectors(model)

    benign_dataloader = load_benign_data(parameters)
    malicious_dataloader = load_malicious_data(parameters)

    if adversarial_vector_type is None:
        # Use all adversarial files
        adversarial_dataloader = load_adversarial_data(parameters)
        dataloaders = [benign_dataloader, malicious_dataloader, adversarial_dataloader]
    else:
        # Use only one type or none
        if adversarial_vector_type == 'natural':
            dataloaders = [benign_dataloader, malicious_dataloader]
        # Load benign, malicious, and adversarial datasets
        else:
            adversarial_dataloader = load_adversarial_data(parameters, method=adversarial_vector_type)
            dataloaders = [benign_dataloader, malicious_dataloader, adversarial_dataloader]

    # Plot over 2D, f(alpha, beta) = L(theta + alpha*delta + beta*eta)
    size = float(parameters['plotting']['plot_size'])
    increment = float(parameters['plotting']['increment'])

    nll_loss_function = nn.NLLLoss(reduce=False)
    # Apply and then reverse the function?
    points = generate_plot_values(model, size, increment, delta_direction, eta_direction, dataloaders, nll_loss_function, is_cuda)

    x_vals, y_vals, z_vals = [p[0] for p in points], [p[1] for p in points], [p[2] for p in points]

    # Save plot as pickle file with same name
    pickle_values = {'x': x_vals, 'y': y_vals, 'z': z_vals}
    pickle.dump(pickle_values, open(os.path.join(output_directory, "{exp_name}_{method}_training_{dim}_size_{incr}_increment_{count}_examples_per_type.p".format(
        exp_name=experiment_name, method=training_method, dim=size, incr=increment, count=num_files_used)), "wb"))

    ### Trisurf 3D plot
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    ax.plot_trisurf(x_vals, y_vals, z_vals, cmap='viridis', edgecolor='none')
    ax.set_xlabel("alpha")
    ax.set_ylabel("beta")
    ax.set_zlabel("Loss")

    if matplotlib.get_backend() != 'Agg':
        plt.show()

    fig.savefig(os.path.join(output_directory, "{exp_name}_loss_landscape_{method}_training_{dim}_size_{incr}_increment_{count}_examples_per_type.png".format(
        method=training_method, incr=increment, exp_name=experiment_name, dim=size, count=num_files_used)))

