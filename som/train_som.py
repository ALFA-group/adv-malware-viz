import sys
import os
sys.path.insert(1, os.path.join(sys.path[0], '..'))

import somoclu

from datasets.datasets import *
from utils.utils import load_parameters
import glob
import os
from random import shuffle
import pickle
import torch
import time
import sys
import random

COLORS = ['b', 'g', 'r', 'm', 'y', 'k']
COLORS_WORDS = ['blue', 'green', 'red', 'magenta', 'yellow', 'black']
ORDERED_TYPES = ['malicious', 'benign', 'dfgsm', 'rfgsm', 'bga', 'bca']

use_synthetic = True
seed_val = 0


def load_vectors(num_points, parameters):
    if use_synthetic:

        if eval(parameters['general']['use_seed']):
            random.seed(seed_val)
            torch.manual_seed(seed_val)

        malicious_dataloader = load_malicious_data(parameters)
        benign_dataloader = load_benign_data(parameters)

        malicious_vectors = []
        benign_vectors = []

        for vec, label in malicious_dataloader:
            malicious_vectors.append(vec)
        for vec, label in benign_dataloader:
            benign_vectors.append(vec)

        malicious_vectors = malicious_vectors[:num_points]
        benign_vectors = benign_vectors[:num_points]

        malicious_vectors = torch.cat(malicious_vectors)
        benign_vectors = torch.cat(benign_vectors)

    else:
        # Load embedded files
        malicious_filepath = parameters['dataset']["malicious_filepath"]
        benign_filepath = parameters['dataset']["benign_filepath"]

        malicious_files = os.listdir(malicious_filepath)
        benign_files = os.listdir(benign_filepath)

        malicious_files = [os.path.join(malicious_filepath, f) for f in malicious_files]
        benign_files = [os.path.join(benign_filepath, f) for f in benign_files]

        shuffle(malicious_files)
        shuffle(benign_files)

        malicious_files = malicious_files[:num_points]
        benign_files = benign_files[:num_points]

        malicious_vectors = [pickle.load(open(f, "rb")) for f in malicious_files]
        benign_vectors = [pickle.load(open(f, "rb")) for f in benign_files]

        malicious_vectors = torch.cat(malicious_vectors)
        benign_vectors = torch.cat(benign_vectors)

    adversarial_filepath = parameters['dataset']['adversarial_filepath']
    string_param = os.path.join(adversarial_filepath, "**")
    adv_files_abs_locs = glob.glob(string_param, recursive=True)

    methods = ['', 'rfgsm_k', 'dfgsm_k', 'bga_k', 'bca_k']
    for method in methods:
        adv_files_abs_locs.remove(os.path.join(adversarial_filepath, method))

    dfgsm_files = list(filter(lambda x: "dfgsm_k" in x, adv_files_abs_locs))
    rfgsm_files = list(filter(lambda x: "rfgsm_k" in x, adv_files_abs_locs))
    bga_files = list(filter(lambda x: "bga_k" in x, adv_files_abs_locs))
    bca_files = list(filter(lambda x: "bca_k" in x, adv_files_abs_locs))

    shuffle(dfgsm_files)
    shuffle(rfgsm_files)
    shuffle(bga_files)
    shuffle(bca_files)

    dfgsm_files = dfgsm_files[:num_points]
    rfgsm_files = rfgsm_files[:num_points]
    bga_files = bga_files[:num_points]
    bca_files = bca_files[:num_points]


    dfgsm_vectors = [pickle.load(open(f, "rb")) for f in dfgsm_files]
    rfgsm_vectors = [pickle.load(open(f, "rb")) for f in rfgsm_files]
    bga_vectors = [pickle.load(open(f, "rb")) for f in bga_files]
    bca_vectors = [pickle.load(open(f, "rb")) for f in bca_files]


    dfgsm_vectors = torch.cat(dfgsm_vectors)
    rfgsm_vectors = torch.cat(rfgsm_vectors)
    bga_vectors = torch.cat(bga_vectors)
    bca_vectors = torch.cat(bca_vectors)

    return malicious_vectors, benign_vectors, dfgsm_vectors, rfgsm_vectors, bga_vectors, bca_vectors


if __name__ == "__main__":
    params_filepath = sys.argv[1]
    parameters = load_parameters(params_filepath)

    attack_num = None
    if len(sys.argv) == 3:
        attack_num = int(sys.argv[2])

    is_cuda = eval(parameters['general']['is_cuda'])

    num_points = int(parameters['hyperparam']['num_vectors_each_type'])
    malicious_vectors, benign_vectors, dfgsm_vectors, rfgsm_vectors, bga_vectors, bca_vectors = load_vectors(num_points, parameters)

    vectors_to_use = [malicious_vectors, benign_vectors, dfgsm_vectors, rfgsm_vectors, bga_vectors, bca_vectors]
    methods_used = ['malicious', 'benign', 'dfgsm', 'rfgsm', 'bga', 'bca']

    if attack_num is not None:
        # Just benign and malicious
        if attack_num == 1:
            vectors_to_use = vectors_to_use[:2]
            methods_used = methods_used[:2]
        else:
            vectors_to_use = list(vectors_to_use[i] for i in [0, 1, attack_num])
            methods_used = list(methods_used[i] for i in [0, 1, attack_num])
    # else just use all methods to train

    print("Methods Used:", methods_used)
    all_vectors = torch.cat(vectors_to_use)

    # Size of SOM and number of epochs to train for
    som_dimension = int(parameters['hyperparam']['som_dimension'])
    n_columns, n_rows = som_dimension, som_dimension

    num_epochs = int(parameters['hyperparam']['som_training_epochs'])
    print("n_columns, n_rows:", n_columns, n_rows)
    print("num_epochs:", num_epochs)

    if is_cuda:
        som_kernel = 1
    else:
        som_kernel = 0

    som = somoclu.Somoclu(n_columns, n_rows, maptype="planar", kerneltype=som_kernel, gridtype="rectangular", initialization='pca', verbose=2)
    som.train(all_vectors.numpy(), epochs=num_epochs)


    # Saving som object as pickle for later loading
    pickle_file_directory = "som_pickles"
    if not os.path.exists(pickle_file_directory):
        os.mkdir(pickle_file_directory)

    pickle.dump(som, open(os.path.join(pickle_file_directory, "{meths}_{numf}_points_{ep}_epochs_{col}_by_{row}.pkl".format(
        meths="_".join(methods_used), numf=num_points, ep=num_epochs, col=n_columns, row=n_rows)), "wb"))

